dataset:
  name: SemanticKITTI
  dataset_path:  # path/to/your/dataset
  cache_dir: ./logs/cache
  class_weights: [55437630, 320797, 541736, 2578735, 3274484, 552662, 184064,
    78858, 240942562, 17294618, 170599734, 6369672, 230413074, 101130274,
    476491114, 9833174, 129609852, 4506626, 1168181]
  test_result_folder: ./test
  test_split: ['11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21']
  training_split: ['00', '01', '02', '03', '04', '05', '06', '07', '09', '10']
  all_split: ['00', '01', '02', '03', '04', '05', '06', '07', '09',
  '08', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21']
  validation_split: ['08']
  use_cache: true
  sampler:
    name: 'SemSegRandomSampler'
model:
  name: RandLANet
  batcher: DefaultBatcher
  ckpt_path: # path/to/your/checkpoint
  dim_feature: 8
  dim_input: 3
  dim_output:
  - 16
  - 64
  - 128
  - 256
  grid_size: 0.06
  ignored_label_inds:
  - 0
  k_n: 16
  num_classes: 19
  num_layers: 4
  num_points: 45056
  sub_sampling_ratio:
  - 4
  - 4
  - 4
  - 4
  t_normalize:
    recentering: []
pipeline:
  name: SemanticSegmentation
  adam_lr: 0.01
  batch_size: 1
  learning_rate: 0.01
  main_log_dir: ./logs
  max_epoch: 100
  save_ckpt_freq: 2
  scheduler_gamma: 0.95
  test_batch_size: 1
  train_sum_dir: train_log
  val_batch_size: 1
  summary:
    record_for: []
    max_pts:
    use_reference: false
    max_outputs: 1
